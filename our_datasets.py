import pandas as pd
import numpy as np
import json
import re
from torch.utils.data import Dataset
import glob
import os
from judge.match import match_reference

advbench_harmful_path = './datasets/advbench/harmful_strings.csv'
red_teaming_path = './datasets/red_team_attempts.jsonl'
self_defense_path = ['./datasets/all_repsonses_gpt.csv',
    './datasets/all_repsonses_llama.csv']

class HarmfulResponseDataset(Dataset):
    # advbench 574
    # self_defense 110
    # red_teaming 748
    def __init__(self, total_number_of_examples=2000):
        data_advbench = self._LoadAdvBench()
        data_selfdefense = self._LoadSelfDefense()
        data_redteaming = self._LoadRedTeaming()
        print (
            'Loading datasets: {} from advbench, {} from self_defense, {} from red_team_attempts.'.format(len(data_advbench), len(data_selfdefense), len(data_redteaming))
        )
        self.data = data_advbench + data_selfdefense + data_redteaming
        self.resource = len(data_advbench)*['advbench'] + len(data_selfdefense)*['selfdefense'] + len(data_redteaming)*['redteaming']

    def _LoadAdvBench(self):
        df = pd.read_csv(advbench_harmful_path)
        return df['target'].values.tolist()

    def _LoadSelfDefense(self):
        selfdefense = []
        for path in self_defense_path:
            df = pd.read_csv(path)
            selfdefense += df.loc[df['is harmful?'] == 'Yes', 'response'].values.tolist()
        return selfdefense

    def _LoadRedTeaming(self):
        with open(red_teaming_path, 'r') as ipt:
            red_team_datas = json.load(ipt)
        saved_rates = []
        saved_harmful = []
        for i in range(len(red_team_datas)):
            rating_info = red_team_datas[i]['rating'] # higher is more successful
            harmful_info = red_team_datas[i]['min_harmlessness_score_transcript'] # lower is more harmful
            saved_rates.append(rating_info)
            saved_harmful.append(harmful_info)
        df = pd.DataFrame()
        df['rating'] = saved_rates
        df['harmlessness'] = saved_harmful
        df['index'] = [i for i in range(len(saved_rates))]
        df = df.sort_values(['rating', 'harmlessness'], ascending=[False, True])
        used_ids = df[(df['harmlessness']<-4) & (df['rating']==4.0)]['index'].tolist()

        used_infos = []
        for used_id in used_ids:
            if used_id == 3373:
                # Error format: "Assistant: Human: ......."
                continue
            one_string = red_team_datas[used_id]['transcript']
            matches = re.findall(r'Assistant:\s*(.*?)(?=(?:Human:|$))', one_string, re.DOTALL)
            matches = [i.strip('Human').strip('Assistant: ') for i in matches]
            lens = np.array([len(i.split()) for i in matches])
            ind = np.argmax(lens)
            used_infos.append(matches[ind])
        return used_infos

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        paragraph = self.data[idx]
        paragraph = paragraph.replace('\n', ' ')
        paragraph = ' '.join(paragraph.split())
        return paragraph, self.resource[idx]