# Offensive Words are from https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/en.
# In this file, we wanna obtain the prediction from judge llms before and after spliting the offensive words.
import pickle as pkl
import torch
from judge.ShieldLM import ShieldLLM_reference
from judge.WildGuard import WildGurad_reference
from judge.LlamaGuard import LlamaGuard_reference
from judge.LlamaGuard2 import LlamaGuard2_reference
from judge.gpt35 import gpt35_reference
from judge.gpt4 import gpt4_reference
from sentence_transformers import SentenceTransformer
import os

def read_phrases(file_path):
    # read phrases from file
    with open(file_path, 'r', encoding='utf-8') as file:
        phrases = [line.strip() for line in file]
    return phrases

def split_words(phrases):
    # split words in phrases with middle point
    split_phrases = []
    for phrase in phrases:
        words = phrase.split()
        split_words = [' '.join([word[:len(word)//2], word[len(word)//2:]]) for word in words]
        split_phrases.append(' '.join(split_words))
    return split_phrases

def split_words_cosine(emb_model, phrase):
    words = phrase.split()
    split_words = []
    for word in words:
        if len(word) == 1:
            split_words.append(word)
            continue
        ori_embedding = emb_model.encode([word])
        cs_outputs = []
        for i in range(len(word)-1):
            split_embedding = emb_model.encode([word[:i+1], word[i+1:]])
            cs_output = torch.nn.functional.cosine_similarity(torch.tensor(split_embedding), torch.tensor(ori_embedding))
            cs_outputs.append(cs_output.mean().item())
        order_token_inds = torch.argsort(torch.tensor(cs_outputs), descending=False)
        used_pos = order_token_inds[0]+1
        split_word = ' '.join([word[:used_pos], word[used_pos:]])
        split_words.append(split_word)
    return ' '.join(split_words)

def paraphrase_cosine(emb_model, phrases):
    split_phrases = []
    for phrase in phrases:
        split_phrase = split_words_cosine(emb_model, phrase)
        split_phrases.append(split_phrase)
    return split_phrases

if __name__ == '__main__':
    file_path = './datasets/en.txt'
    phrases = read_phrases(file_path)
    # since the final one is one emoji, we remove it, and dicuss emojis in another file.
    phrases = phrases[:-1]
    splited_phrases = split_words(phrases)

    emb_model = SentenceTransformer('sentence-transformers/gtr-t5-xl', cache_folder=os.getenv('Surrogate_Model_PATH'))
    cs_splited_phrases = paraphrase_cosine(emb_model, phrases)

    save_dict = {}
    for func in [ShieldLLM_reference, WildGurad_reference, LlamaGuard_reference, LlamaGuard2_reference]:
        pres, conts = func(phrases, batch_size=1)
        sp_pres, sp_conts = func(splited_phrases, batch_size=1)
        cs_pres, cs_conts = func(cs_splited_phrases, batch_size=1)
        
        save_dict[f'{func.__name__}'] = {}
        for ind,phrase in enumerate(phrases):
            save_dict[f'{func.__name__}'][phrase] = [pres[ind], sp_pres[ind], cs_pres[ind]]

    with open('offensive_words_judge.pkl', 'wb') as file:
        pkl.dump(save_dict, file)